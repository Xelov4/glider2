"""
üîç Module d'Analyse d'Images - D√©tection de Cartes et OCR
========================================================

Ce module g√®re la reconnaissance visuelle des √©l√©ments de poker :
- D√©tection des cartes (OCR + ML)
- Reconnaissance des jetons et montants
- Extraction de texte avec Tesseract
- Validation et filtrage des r√©sultats

FONCTIONNALIT√âS
===============

‚úÖ D√©tection OCR des cartes
‚úÖ D√©tection ML des cartes
‚úÖ OCR robuste pour les montants
‚úÖ Validation automatique des r√©sultats
‚úÖ Gestion d'erreurs compl√®te

M√âTHODES PRINCIPALES
====================

- detect_cards() : D√©tection principale des cartes
- extract_text() : OCR avec Tesseract
- detect_chips() : Reconnaissance des jetons
- validate_card() : Validation des cartes d√©tect√©es

VERSION: 3.0.0 - AVEC ML
DERNI√àRE MISE √Ä JOUR: 2025-01-XX
"""

import cv2
import numpy as np
import pytesseract
import logging
from typing import List, Optional, Tuple, Dict
from dataclasses import dataclass

@dataclass
class Card:
    rank: str
    suit: str
    confidence: float
    position: Tuple[int, int]

class ImageAnalyzer:
    """
    Analyseur d'images pour la d√©tection de cartes et OCR
    """
    
    def __init__(self, tesseract_path: str = None):
        self.logger = logging.getLogger(__name__)
        
        # Configuration Tesseract
        if tesseract_path:
            pytesseract.pytesseract.tesseract_cmd = tesseract_path
        
        # Mapping OCR pour corriger les erreurs courantes
        self.ocr_mapping = {
            '0': 'O',
            '1': 'I',
            'l': 'I',
            'I': 'I',
            'O': '0',
            'S': '5',
            'G': '6',
            'B': '8'
        }
        
        # NOUVEAU: Cache intelligent pour performance
        self.image_cache = {}
        self.decision_cache = {}
        self.last_capture_time = 0
        self.cache_ttl = 0.05  # 50ms TTL pour le cache
        
        # NOUVEAU: M√©triques de performance optimis√©es
        self.performance_metrics = {
            'capture_times': [],
            'decision_times': [],
            'ocr_times': [],
            'total_cycles': 0,
            'avg_cycle_time': 0,
            'cache_hits': 0,
            'cache_misses': 0
        }
        
        # NOUVEAU: Configuration de performance ultra-optimis√©e
        self.performance_config = {
            'capture_interval': 0.005,  # 5ms entre captures
            'decision_timeout': 0.02,  # 20ms max pour d√©cision
            'cache_enabled': True,
            'parallel_processing': False,  # D√©sactiv√© pour stabilit√©
            'ultra_fast_mode': True,
            'max_cache_size': 100,  # Limite la taille du cache
            'memory_cleanup_interval': 100  # Nettoyage tous les 100 cycles
        }

    def detect_cards(self, image: np.ndarray, region_name: str = "hand_area") -> List[Card]:
        """
        D√©tecte les cartes avec syst√®me hybride optimis√©
        """
        try:
            self.logger.debug(f"üîß D√©tection cartes {region_name} - Image: {image.shape}")
            
            # SYST√àME HYBRIDE: Workflow optimis√© avec images haute qualit√©
            
            # 1. MACHINE LEARNING (priorit√© absolue)
            try:
                from .card_ml_detector import CardMLDetector
                ml_detector = CardMLDetector()
                if ml_detector.is_trained:
                    ml_cards = ml_detector.detect_cards_ml(image)
                    if ml_cards:
                        # Convertir les CardFeature en Card
                        converted_cards = []
                        for ml_card in ml_cards:
                            card = Card(
                                rank=ml_card.rank,
                                suit=ml_card.suit,
                                confidence=ml_card.confidence,
                                position=(0, 0)
                            )
                            converted_cards.append(card)
                        
                        self.logger.debug(f"‚úÖ ML d√©tect√© {len(converted_cards)} cartes: {[f'{c.rank}{c.suit}' for c in converted_cards]}")
                        return converted_cards
            except Exception as e:
                self.logger.debug(f"ML non disponible: {e}")
            
            # 2. OCR optimis√© pour images haute qualit√©
            ocr_cards = self._detect_cards_ocr_optimized(image)
            if ocr_cards:
                self.logger.debug(f"‚úÖ OCR d√©tect√© {len(ocr_cards)} cartes: {[f'{c.rank}{c.suit}' for c in ocr_cards]}")
                return ocr_cards
            
            # 3. D√©tection ultra-rapide
            fast_cards = self._detect_cards_ultra_fast(image)
            if fast_cards:
                self.logger.debug(f"‚úÖ Fast d√©tect√© {len(fast_cards)} cartes: {[f'{c.rank}{c.suit}' for c in fast_cards]}")
                return fast_cards
            
            # 4. Contours (fallback)
            contour_cards = self._detect_cards_by_contours(image)
            if contour_cards:
                self.logger.debug(f"‚úÖ Contours d√©tect√© {len(contour_cards)} cartes: {[f'{c.rank}{c.suit}' for c in contour_cards]}")
                return contour_cards
            
            # 5. Couleurs (dernier recours)
            color_cards = self._detect_cards_by_color(image)
            if color_cards:
                self.logger.debug(f"‚úÖ Couleurs d√©tect√© {len(color_cards)} cartes: {[f'{c.rank}{c.suit}' for c in color_cards]}")
                return color_cards
            
            self.logger.debug(f"‚ùå Aucune carte d√©tect√©e dans {region_name}")
            return []
            
        except Exception as e:
            self.logger.error(f"Erreur d√©tection cartes: {e}")
            return []

    def _detect_cards_ultra_fast(self, image: np.ndarray) -> List[Card]:
        """
        D√©tection ultra-rapide des cartes (m√©thode la plus efficace)
        """
        try:
            cards = []
            
            # NOUVEAU: OCR ultra-rapide avec configuration optimis√©e
            config = '--oem 3 --psm 6 -c tessedit_char_whitelist=23456789TJQKA'
            
            # Pr√©traitement minimal
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image.copy()
            
            # Am√©lioration du contraste
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
            enhanced = clahe.apply(gray)
            
            # OCR
            text = pytesseract.image_to_string(enhanced, config=config)
            clean_text = text.strip().upper()
            
            self.logger.debug(f"Texte OCR ultra-rapide: '{clean_text}'")
            
            # NOUVEAU: Parser intelligent du texte
            detected_ranks = []
            for char in clean_text:
                if char in '23456789TJQKA':
                    detected_ranks.append(char)
            
            # NOUVEAU: D√©tection de couleur par analyse d'image
            if detected_ranks:
                # Analyser les couleurs dans l'image
                color_analysis = self._analyze_colors_ultra_fast(image)
                
                # Associer rangs et couleurs
                for rank in detected_ranks:
                    # D√©terminer la couleur bas√©e sur la position et l'analyse
                    suit = self._determine_suit_by_position_and_color(image, rank, color_analysis)
                    
                    card = Card(
                        rank=rank,
                        suit=suit,
                        confidence=0.8,  # Confiance √©lev√©e pour l'OCR
                        position=(0, 0)
                    )
                    cards.append(card)
                    self.logger.debug(f"Carte d√©tect√©e ultra-rapide: {rank}{suit}")
            
            return cards
            
        except Exception as e:
            self.logger.error(f"Erreur d√©tection ultra-rapide: {e}")
            return []

    def _analyze_colors_ultra_fast(self, image: np.ndarray) -> Dict:
        """
        Analyse ultra-rapide des couleurs dans l'image
        """
        try:
            # Conversion HSV
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
            
            # Masques pour rouge et noir
            # Rouge (‚ô•, ‚ô¶)
            lower_red1 = np.array([0, 50, 50])
            upper_red1 = np.array([10, 255, 255])
            lower_red2 = np.array([170, 50, 50])
            upper_red2 = np.array([180, 255, 255])
            
            mask_red1 = cv2.inRange(hsv, lower_red1, upper_red1)
            mask_red2 = cv2.inRange(hsv, lower_red2, upper_red2)
            mask_red = cv2.bitwise_or(mask_red1, mask_red2)
            
            # Noir (‚ô†, ‚ô£)
            lower_black = np.array([0, 0, 0])
            upper_black = np.array([180, 255, 50])
            mask_black = cv2.inRange(hsv, lower_black, upper_black)
            
            # Compter les pixels
            red_pixels = cv2.countNonZero(mask_red)
            black_pixels = cv2.countNonZero(mask_black)
            total_pixels = image.shape[0] * image.shape[1]
            
            return {
                'red_pixels': red_pixels,
                'black_pixels': black_pixels,
                'total_pixels': total_pixels,
                'red_ratio': red_pixels / total_pixels if total_pixels > 0 else 0,
                'black_ratio': black_pixels / total_pixels if total_pixels > 0 else 0
            }
            
        except Exception as e:
            self.logger.debug(f"Erreur analyse couleurs ultra-rapide: {e}")
            return {'red_pixels': 0, 'black_pixels': 0, 'total_pixels': 1, 'red_ratio': 0, 'black_ratio': 0}

    def _determine_suit_by_position_and_color(self, image: np.ndarray, rank: str, color_analysis: Dict) -> str:
        """
        D√©termine la couleur d'une carte bas√©e sur la position et l'analyse de couleur
        """
        try:
            # NOUVEAU: Logique intelligente bas√©e sur les ratios de couleur
            red_ratio = color_analysis['red_ratio']
            black_ratio = color_analysis['black_ratio']
            
            # Seuils pour d√©tecter les couleurs
            color_threshold = 0.05  # 5% de pixels color√©s
            
            if red_ratio > color_threshold:
                # Rouge d√©tect√© - d√©terminer ‚ô• ou ‚ô¶
                if red_ratio > 0.1:  # Beaucoup de rouge
                    return '‚ô•'
                else:
                    return '‚ô¶'
            elif black_ratio > color_threshold:
                # Noir d√©tect√© - d√©terminer ‚ô† ou ‚ô£
                if black_ratio > 0.1:  # Beaucoup de noir
                    return '‚ô†'
                else:
                    return '‚ô£'
            else:
                # Pas de couleur claire d√©tect√©e
                # NOUVEAU: Heuristique bas√©e sur le rang
                if rank in ['A', 'K', 'Q', 'J']:
                    # Figures - plus souvent noires
                    return '‚ô†'
                elif rank in ['T', '9', '8']:
                    # 10-8 - plus souvent rouges
                    return '‚ô•'
                else:
                    # Chiffres - alterner
                    return '‚ô£'
            
        except Exception as e:
            self.logger.debug(f"Erreur d√©termination couleur: {e}")
            return '?'  # Couleur inconnue

    def _detect_cards_ocr_optimized(self, image: np.ndarray) -> List[Card]:
        """
        OCR optimis√© pour les cartes avec plusieurs configurations
        """
        cards = []
        
        # Configuration 1: OCR standard
        config1 = '--oem 3 --psm 6 -c tessedit_char_whitelist=23456789TJQKA‚ô†‚ô•‚ô¶‚ô£'
        cards.extend(self._try_ocr_config(image, config1))
        
        # Configuration 2: OCR pour texte dense
        config2 = '--oem 3 --psm 8 -c tessedit_char_whitelist=23456789TJQKA‚ô†‚ô•‚ô¶‚ô£'
        cards.extend(self._try_ocr_config(image, config2))
        
        # Configuration 3: OCR pour caract√®res individuels
        config3 = '--oem 3 --psm 10 -c tessedit_char_whitelist=23456789TJQKA‚ô†‚ô•‚ô¶‚ô£'
        cards.extend(self._try_ocr_config(image, config3))
        
        # D√©dupliquer et valider
        unique_cards = self._deduplicate_cards(cards)
        return [card for card in unique_cards if self._validate_card(card)]

    def _try_ocr_config(self, image: np.ndarray, config: str) -> List[Card]:
        """
        Essaie une configuration OCR sp√©cifique
        """
        try:
            # Pr√©traitement sp√©cifique
            processed = self._preprocess_for_ocr(image)
            
            # OCR avec la configuration
            text = pytesseract.image_to_string(
                processed, 
                config=config,
                output_type=pytesseract.Output.DICT
            )
            
            # Parser le r√©sultat
            return self._parse_ocr_text_advanced(text['text'])
            
        except Exception as e:
            self.logger.debug(f"OCR config √©chou√©e: {e}")
            return []

    def _preprocess_for_ocr(self, image: np.ndarray) -> np.ndarray:
        """
        Pr√©traitement optimis√© pour la d√©tection de cartes
        """
        try:
            # Conversion en niveaux de gris
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image.copy()
            
            # Redimensionnement pour am√©liorer l'OCR
            height, width = gray.shape
            if width < 100:  # Image trop petite
                scale = 2.0
                new_width = int(width * scale)
                new_height = int(height * scale)
                gray = cv2.resize(gray, (new_width, new_height), interpolation=cv2.INTER_CUBIC)
            
            # Am√©lioration du contraste avec CLAHE
            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
            enhanced = clahe.apply(gray)
            
            # R√©duction du bruit avec filtre bilat√©ral
            denoised = cv2.bilateralFilter(enhanced, 9, 75, 75)
            
            # Seuillage adaptatif multiple
            # M√©thode 1: Seuillage adaptatif gaussien
            binary1 = cv2.adaptiveThreshold(
                denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                cv2.THRESH_BINARY, 11, 2
            )
            
            # M√©thode 2: Seuillage adaptatif moyen
            binary2 = cv2.adaptiveThreshold(
                denoised, 255, cv2.ADAPTIVE_THRESH_MEAN_C, 
                cv2.THRESH_BINARY, 15, 3
            )
            
            # M√©thode 3: Seuillage Otsu
            _, binary3 = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            # Combiner les r√©sultats
            combined = cv2.bitwise_and(binary1, binary2)
            combined = cv2.bitwise_or(combined, binary3)
            
            # Morphologie pour nettoyer
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
            cleaned = cv2.morphologyEx(combined, cv2.MORPH_CLOSE, kernel)
            
            return cleaned
            
        except Exception as e:
            self.logger.error(f"Erreur pr√©traitement OCR: {e}")
            return image

    def _parse_ocr_text_advanced(self, text: str) -> List[Card]:
        """
        Parse avanc√© du texte OCR avec plus de patterns
        """
        cards = []
        try:
            # Nettoyer le texte
            clean_text = text.strip().upper()
            self.logger.debug(f"Texte OCR brut: '{clean_text}'")
            
            # Pattern 1: "AS KH QD JC" (rang + couleur)
            pattern1 = r'([2-9TJQKA])([‚ô†‚ô•‚ô¶‚ô£SHDC])'
            import re
            matches1 = re.findall(pattern1, clean_text)
            for rank, suit in matches1:
                card = Card(
                    rank=rank,
                    suit=self._normalize_suit(suit),
                    confidence=0.9,
                    position=(0, 0)
                )
                cards.append(card)
            
            # Pattern 2: "A‚ô† K‚ô•" (avec symboles)
            pattern2 = r'([2-9TJQKA])([‚ô†‚ô•‚ô¶‚ô£])'
            matches2 = re.findall(pattern2, clean_text)
            for rank, suit in matches2:
                card = Card(
                    rank=rank,
                    suit=suit,
                    confidence=0.95,
                    position=(0, 0)
                )
                cards.append(card)
            
            # Pattern 3: Caract√®res individuels proches
            if len(clean_text) >= 2:
                for i in range(len(clean_text) - 1):
                    char1 = clean_text[i]
                    char2 = clean_text[i + 1]
                    
                    # V√©rifier si c'est un rang + couleur
                    if char1 in '23456789TJQKA' and char2 in '‚ô†‚ô•‚ô¶‚ô£SHDC':
                        card = Card(
                            rank=char1,
                            suit=self._normalize_suit(char2),
                            confidence=0.8,
                            position=(0, 0)
                        )
                        cards.append(card)
            
            # NOUVEAU: Pattern 4 - D√©tection de rangs seuls (pour cartes sans couleur visible)
            # Chercher tous les rangs dans le texte
            rank_pattern = r'([2-9TJQKA])'
            rank_matches = re.findall(rank_pattern, clean_text)
            
            # Si on trouve des rangs mais pas de couleurs, cr√©er des cartes avec couleur par d√©faut
            if rank_matches and not cards:
                for rank in rank_matches:
                    # Cr√©er une carte avec couleur par d√©faut
                    card = Card(
                        rank=rank,
                        suit='?',  # Couleur inconnue
                        confidence=0.6,  # Confiance r√©duite
                        position=(0, 0)
                    )
                    cards.append(card)
                    self.logger.debug(f"Carte d√©tect√©e (rang seul): {rank}?")
            
            # NOUVEAU: Pattern 5 - D√©tection de doubles (paires)
            # Chercher les r√©p√©titions de rangs
            for rank in '23456789TJQKA':
                count = clean_text.count(rank)
                if count >= 2:
                    # Probablement une paire
                    card = Card(
                        rank=rank,
                        suit='?',
                        confidence=0.7,
                        position=(0, 0)
                    )
                    cards.append(card)
                    self.logger.debug(f"Paire d√©tect√©e: {rank}{rank}")
            
            # Corriger les erreurs OCR courantes
            corrected_cards = []
            for card in cards:
                # Corriger le rang
                corrected_rank = self.ocr_mapping.get(card.rank, card.rank)
                if corrected_rank != card.rank:
                    card.rank = corrected_rank
                    card.confidence *= 0.9  # R√©duire la confiance si correction
                
                corrected_cards.append(card)
            
            # D√©dupliquer les cartes
            unique_cards = self._deduplicate_cards(corrected_cards)
            
            self.logger.debug(f"Cartes pars√©es: {[f'{c.rank}{c.suit}' for c in unique_cards]}")
            return unique_cards
            
        except Exception as e:
            self.logger.error(f"Erreur parsing OCR avanc√©: {e}")
            return []

    def _detect_cards_by_contours(self, image: np.ndarray) -> List[Card]:
        """
        D√©tecte les cartes par analyse de contours
        """
        try:
            cards = []
            
            # Conversion en niveaux de gris
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image.copy()
            
            # Seuillage adaptatif
            thresh = cv2.adaptiveThreshold(
                gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                cv2.THRESH_BINARY, 11, 2
            )
            
            # Recherche de contours
            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            for contour in contours:
                area = cv2.contourArea(contour)
                if area > 100:  # Filtre les petits contours
                    # Approximation du rectangle
                    rect = cv2.minAreaRect(contour)
                    box = cv2.boxPoints(rect)
                    box = np.int0(box)
                    
                    # Extraction de la r√©gion
                    x, y, w, h = cv2.boundingRect(contour)
                    card_region = image[y:y+h, x:x+w]
                    
                    # Analyser la r√©gion
                    card = self._analyze_card_region(card_region)
                    if card:
                        cards.append(card)
            
            return cards
            
        except Exception as e:
            self.logger.error(f"Erreur d√©tection par contours: {e}")
            return []

    def _analyze_card_region(self, card_region: np.ndarray) -> Optional[Card]:
        """
        Analyse une r√©gion de carte pour d√©terminer rank et suit
        """
        try:
            if card_region.size == 0:
                return None
                
            # OCR sur la r√©gion
            text = pytesseract.image_to_string(
                card_region, 
                config='--oem 3 --psm 6 -c tessedit_char_whitelist=23456789TJQKA‚ô†‚ô•‚ô¶‚ô£',
                output_type=pytesseract.Output.DICT
            )
            
            # Analyser le texte
            clean_text = text['text'].strip().upper()
            if len(clean_text) >= 2:
                rank = clean_text[0]
                suit = clean_text[1]
                
                # Valider
                if rank in '23456789TJQKA' and suit in '‚ô†‚ô•‚ô¶‚ô£SHDC':
                    return Card(
                        rank=rank,
                        suit=self._normalize_suit(suit),
                        confidence=0.7,
                        position=(0, 0)
                    )
            
            return None
            
        except Exception as e:
            self.logger.debug(f"Erreur analyse r√©gion carte: {e}")
            return None

    def _detect_cards_by_color(self, image: np.ndarray) -> List[Card]:
        """
        D√©tecte les cartes par analyse de couleur (rouge/noir)
        """
        try:
            cards = []
            
            # Conversion en HSV pour meilleure d√©tection des couleurs
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
            
            # D√©tection du rouge (‚ô•, ‚ô¶) - deux plages HSV
            lower_red1 = np.array([0, 100, 100])
            upper_red1 = np.array([10, 255, 255])
            lower_red2 = np.array([170, 100, 100])
            upper_red2 = np.array([180, 255, 255])
            
            mask_red1 = cv2.inRange(hsv, lower_red1, upper_red1)
            mask_red2 = cv2.inRange(hsv, lower_red2, upper_red2)
            mask_red = cv2.bitwise_or(mask_red1, mask_red2)
            
            # D√©tection du noir (‚ô†, ‚ô£)
            lower_black = np.array([0, 0, 0])
            upper_black = np.array([180, 255, 30])
            mask_black = cv2.inRange(hsv, lower_black, upper_black)
            
            # Analyser les r√©gions de couleur
            red_regions = self._find_color_regions(mask_red, 'red')
            black_regions = self._find_color_regions(mask_black, 'black')
            
            # Combiner avec OCR pour d√©tecter les rangs
            ocr_cards = self._detect_cards_ocr_optimized(image)
            
            # Associer couleurs et rangs
            cards = self._associate_colors_with_ranks(ocr_cards, red_regions, black_regions, image)
            
            return cards
            
        except Exception as e:
            self.logger.error(f"Erreur d√©tection par couleur: {e}")
            return []

    def _find_color_regions(self, mask: np.ndarray, color_type: str) -> List[Dict]:
        """
        Trouve les r√©gions de couleur sp√©cifique dans l'image
        """
        regions = []
        try:
            # Recherche de contours dans le masque
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            for contour in contours:
                area = cv2.contourArea(contour)
                if area > 50:  # Filtre les petits contours
                    x, y, w, h = cv2.boundingRect(contour)
                    regions.append({
                        'area': area,
                        'position': (x, y),
                        'size': (w, h),
                        'color_type': color_type
                    })
            
            return regions
            
        except Exception as e:
            self.logger.error(f"Erreur recherche r√©gions couleur: {e}")
            return []

    def _associate_colors_with_ranks(self, ocr_cards: List[Card], red_regions: List[Dict], 
                                   black_regions: List[Dict], image: np.ndarray) -> List[Card]:
        """
        Associe les couleurs d√©tect√©es avec les rangs OCR
        """
        try:
            cards = []
            
            for card in ocr_cards:
                # Trouver la meilleure correspondance de couleur
                best_suit = self._find_best_color_match(card, red_regions, black_regions, image)
                
                if best_suit:
                    card.suit = best_suit
                    cards.append(card)
                else:
                    # Garder la carte m√™me sans couleur
                    cards.append(card)
            
            return cards
            
        except Exception as e:
            self.logger.error(f"Erreur association couleurs: {e}")
            return ocr_cards

    def _find_best_color_match(self, card: Card, red_regions: List[Dict], 
                              black_regions: List[Dict], image: np.ndarray) -> Optional[str]:
        """
        Trouve la meilleure correspondance de couleur pour une carte
        """
        try:
            # Analyser la r√©gion autour de la carte
            card_region = self._get_card_region(card, image)
            if card_region is None:
                return None
            
            # Compter les pixels rouges et noirs dans la r√©gion
            hsv_region = cv2.cvtColor(card_region, cv2.COLOR_BGR2HSV)
            
            # Masques pour rouge et noir
            mask_red = cv2.inRange(hsv_region, np.array([0, 100, 100]), np.array([10, 255, 255]))
            mask_red2 = cv2.inRange(hsv_region, np.array([170, 100, 100]), np.array([180, 255, 255]))
            mask_red_total = cv2.bitwise_or(mask_red, mask_red2)
            
            mask_black = cv2.inRange(hsv_region, np.array([0, 0, 0]), np.array([180, 255, 30]))
            
            red_pixels = cv2.countNonZero(mask_red_total)
            black_pixels = cv2.countNonZero(mask_black)
            total_pixels = card_region.shape[0] * card_region.shape[1]
            
            # D√©terminer la couleur dominante
            if red_pixels > black_pixels and red_pixels > total_pixels * 0.1:
                # D√©terminer si ‚ô• ou ‚ô¶ bas√© sur la forme
                return self._determine_red_suit(card_region)
            elif black_pixels > red_pixels and black_pixels > total_pixels * 0.1:
                # D√©terminer si ‚ô† ou ‚ô£ bas√© sur la forme
                return self._determine_black_suit(card_region)
            
            return None
            
        except Exception as e:
            self.logger.debug(f"Erreur correspondance couleur: {e}")
            return None

    def _get_card_region(self, card: Card, image: np.ndarray) -> Optional[np.ndarray]:
        """
        Extrait la r√©gion d'une carte depuis l'image
        """
        try:
            # Pour l'instant, utiliser une r√©gion par d√©faut
            # TODO: Am√©liorer avec la position r√©elle de la carte
            height, width = image.shape[:2]
            region_size = min(width, height) // 4
            
            # R√©gion centrale par d√©faut
            x = width // 4
            y = height // 4
            w = region_size
            h = region_size
            
            return image[y:y+h, x:x+w]
            
        except Exception as e:
            self.logger.debug(f"Erreur extraction r√©gion carte: {e}")
            return None

    def _determine_red_suit(self, card_region: np.ndarray) -> str:
        """
        D√©termine si c'est ‚ô• ou ‚ô¶ bas√© sur la forme
        """
        try:
            # Conversion en niveaux de gris
            gray = cv2.cvtColor(card_region, cv2.COLOR_BGR2GRAY)
            
            # Seuillage pour isoler la forme
            _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)
            
            # Recherche de contours
            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            for contour in contours:
                area = cv2.contourArea(contour)
                if area > 100:
                    # Analyser la forme
                    hull = cv2.convexHull(contour)
                    hull_area = cv2.contourArea(hull)
                    solidity = float(area) / hull_area
                    
                    # ‚ô• a g√©n√©ralement une solidit√© plus √©lev√©e (forme pleine)
                    if solidity > 0.9:
                        return '‚ô•'
                    else:
                        return '‚ô¶'
            
            # Par d√©faut, retourner ‚ô•
            return '‚ô•'
            
        except Exception as e:
            self.logger.debug(f"Erreur d√©termination rouge: {e}")
            return '‚ô•'

    def _determine_black_suit(self, card_region: np.ndarray) -> str:
        """
        D√©termine si c'est ‚ô† ou ‚ô£ bas√© sur la forme
        """
        try:
            # Conversion en niveaux de gris
            gray = cv2.cvtColor(card_region, cv2.COLOR_BGR2GRAY)
            
            # Seuillage pour isoler la forme
            _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)
            
            # Recherche de contours
            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            for contour in contours:
                area = cv2.contourArea(contour)
                if area > 100:
                    # Analyser la forme
                    hull = cv2.convexHull(contour)
                    hull_area = cv2.contourArea(hull)
                    solidity = float(area) / hull_area
                    
                    # ‚ô† a g√©n√©ralement une solidit√© plus √©lev√©e (forme pleine)
                    if solidity > 0.9:
                        return '‚ô†'
                    else:
                        return '‚ô£'
            
            # Par d√©faut, retourner ‚ô†
            return '‚ô†'
            
        except Exception as e:
            self.logger.debug(f"Erreur d√©termination noir: {e}")
            return '‚ô†'

    def _deduplicate_cards(self, cards: List[Card]) -> List[Card]:
        """
        D√©duplique les cartes d√©tect√©es
        """
        unique_cards = []
        seen = set()
        
        for card in cards:
            card_key = f"{card.rank}{card.suit}"
            if card_key not in seen:
                seen.add(card_key)
                unique_cards.append(card)
        
        return unique_cards

    def _normalize_suit(self, suit: str) -> str:
        """
        Normalise les symboles de couleur
        """
        suit_mapping = {
            'S': '‚ô†', 'H': '‚ô•', 'D': '‚ô¶', 'C': '‚ô£',
            '‚ô†': '‚ô†', '‚ô•': '‚ô•', '‚ô¶': '‚ô¶', '‚ô£': '‚ô£',
            '?': '?'
        }
        return suit_mapping.get(suit, '?')

    def _validate_card(self, card: Card) -> bool:
        """Valide une carte d√©tect√©e"""
        try:
            # V√©rifier que le rang est valide
            valid_ranks = ['2', '3', '4', '5', '6', '7', '8', '9', 'T', 'J', 'Q', 'K', 'A']
            if card.rank not in valid_ranks:
                self.logger.debug(f"Rang invalide: {card.rank}")
                return False
            
            # V√©rifier que la couleur est valide (incluant '?' pour inconnue)
            valid_suits = ['‚ô†', '‚ô•', '‚ô¶', '‚ô£', '?']
            if card.suit not in valid_suits:
                self.logger.debug(f"Couleur invalide: {card.suit}")
                return False
            
            # V√©rifier la confiance (seuil plus bas pour les cartes avec couleur inconnue)
            min_confidence = 0.05 if card.suit == '?' else 0.1
            if card.confidence < min_confidence:
                self.logger.debug(f"Confiance trop faible: {card.confidence}")
                return False
            
            return True
            
        except Exception as e:
            self.logger.debug(f"Erreur validation carte: {e}")
            return False

    def extract_text(self, image: np.ndarray, region_name: str = "unknown") -> str:
        """
        Extrait du texte d'une image avec OCR
        """
        try:
            # Configuration OCR pour le texte g√©n√©ral
            config = '--oem 3 --psm 6'
            
            # Pr√©traitement
            processed = self._preprocess_for_ocr(image)
            
            # Extraction
            text = pytesseract.image_to_string(processed, config=config)
            
            # Nettoyage
            clean_text = text.strip()
            
            self.logger.debug(f"Texte extrait de {region_name}: '{clean_text}'")
            return clean_text
            
        except Exception as e:
            self.logger.error(f"Erreur extraction texte: {e}")
            return ""

    def detect_chips(self, image: np.ndarray) -> List[int]:
        """
        D√©tecte les jetons dans une image
        """
        try:
            text = self.extract_text(image, "chips")
            
            # Chercher les nombres
            import re
            numbers = re.findall(r'\d+', text)
            
            chips = []
            for num in numbers:
                try:
                    chips.append(int(num))
                except ValueError:
                    continue
            
            self.logger.debug(f"Jetons d√©tect√©s: {chips}")
            return chips
            
        except Exception as e:
            self.logger.error(f"Erreur d√©tection jetons: {e}")
            return []

    def debug_card_detection(self, image: np.ndarray, region_name: str = "debug") -> Dict:
        """
        M√©thode de debug pour analyser la d√©tection de cartes
        """
        debug_info = {
            'region': region_name,
            'image_shape': image.shape if image is not None else None,
            'ocr_results': [],
            'detected_cards': [],
            'errors': []
        }
        
        try:
            if image is None or image.size == 0:
                debug_info['errors'].append("Image vide")
                return debug_info
            
            # Test OCR avec diff√©rentes configurations
            configs = [
                ('Standard', '--oem 3 --psm 6'),
                ('Dense', '--oem 3 --psm 8'),
                ('Single char', '--oem 3 --psm 10'),
                ('Cards only', '--oem 3 --psm 6 -c tessedit_char_whitelist=23456789TJQKA‚ô†‚ô•‚ô¶‚ô£'),
                ('Cards dense', '--oem 3 --psm 8 -c tessedit_char_whitelist=23456789TJQKA‚ô†‚ô•‚ô¶‚ô£'),
            ]
            
            for config_name, config in configs:
                try:
                    processed = self._preprocess_for_ocr(image)
                    text = pytesseract.image_to_string(processed, config=config)
                    debug_info['ocr_results'].append({
                        'config': config_name,
                        'text': text.strip(),
                        'length': len(text.strip())
                    })
                except Exception as e:
                    debug_info['errors'].append(f"OCR {config_name}: {e}")
            
            # Test de d√©tection compl√®te
            detected_cards = self.detect_cards(image, region_name)
            debug_info['detected_cards'] = [f"{c.rank}{c.suit}" for c in detected_cards]
            
            # Analyse des couleurs
            try:
                hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
                red_pixels = cv2.countNonZero(cv2.inRange(hsv, np.array([0, 100, 100]), np.array([10, 255, 255])))
                black_pixels = cv2.countNonZero(cv2.inRange(hsv, np.array([0, 0, 0]), np.array([180, 255, 30])))
                debug_info['color_analysis'] = {
                    'red_pixels': red_pixels,
                    'black_pixels': black_pixels,
                    'total_pixels': image.shape[0] * image.shape[1]
                }
            except Exception as e:
                debug_info['errors'].append(f"Analyse couleur: {e}")
            
            return debug_info
            
        except Exception as e:
            debug_info['errors'].append(f"Erreur g√©n√©rale: {e}")
            return debug_info 